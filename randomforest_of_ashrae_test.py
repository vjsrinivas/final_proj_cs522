# -*- coding: utf-8 -*-
"""Copy of ASHRAE_Test

Automatically generated by Colaboratory.

Original file is located at
  https://colab.research.google.com/drive/1ijjD4AaJ2PoW2EaGf9N6z6vDX7UitcrJ

# Reduce Memory Footprint
"""
import pandas as pd
import numpy as np
import scipy
from sklearn.metrics import mean_squared_log_error
from data import data
from sklearn.metrics import r2_score as sk_r2score


clean_train = pd.read_csv('colab_data.csv') # with ALL 14 features

# reduce memory:
clean_train['timestamp'] = clean_train['timestamp'].astype(np.int64)
clean_train['meter'] = clean_train['meter'].astype(np.uint8)
clean_train['site_id'] = clean_train['site_id'].astype(np.int64)
clean_train['primary_use'] = clean_train['primary_use'].astype(np.int64)

clean_train = clean_train.drop(columns='floor_count')
clean_train = clean_train.drop(columns='year_built')
clean_train # NOTE: meter_reading is the target variable so is the 14th feature

clean_train.info()

#Taking random 10% sample of the data as test sample
sample_train=clean_train.sample(frac=0.10)

#The new shape of the data
sample_train.shape

#Spliting into features and target, so we remove the target
X = sample_train.drop('meter_reading', axis = 1)
Y = sample_train['meter_reading']

X.shape

Y.shape

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)

# PCA:
from src import pca
#X_train = pca.pca(X_train, 3)
#X_test = pca.pca(X_test, 3)

#Standardizing the features we using standard scalar
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_scaled = scaler.transform(X_train)

from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor(n_estimators = 20, random_state =30)
model.fit(X_train_scaled,Y_train)

import time
Y_predict = model.predict(X_test_scaled)

X_test_scaled.shape

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

mse = mean_squared_error(Y_test,Y_predict)
mbe = mean_absolute_error(Y_test,Y_predict)

def rmsle_metric(Y_test,Y_predict):
  #Convert the pandas series to array
  Y_test_array = Y_test.to_numpy()
  n = len(Y_test_array)
  value_list = []
  for i in range(n):
    pri = Y_predict[i]
    act = Y_test_array[i]
    log_pred = np.log(pri + 1)
    log_act = np.log(act + 1)
    value = (log_pred - log_act)**2
    value_list.append(value)

  msle = sum(value_list)/n
  rmsle = np.sqrt(msle)
  return rmsle

rmsle_value = rmsle_metric(Y_test,Y_predict)
print(rmsle_value)
rmsle_metric = np.sqrt(mean_squared_log_error(Y_test,Y_predict))
print(rmsle_value)
_r2 = sk_r2score(Y_test, Y_predict)
print("R2 Score:", _r2)
exit()

del Y_test
del Y_predict
del X_test_scaled
del X_test
del X_train
del clean_train
# ==================================
# TESTING:

clean_test = pd.read_csv('colab_data_test.csv') # with ALL 14 features

# reduce memory:
clean_test['timestamp'] = clean_test['timestamp'].astype(np.int64)
clean_test['meter'] = clean_test['meter'].astype(np.uint8)
clean_test['site_id'] = clean_test['site_id'].astype(np.int64)
clean_test['primary_use'] = clean_test['primary_use'].astype(np.int64)

clean_test = clean_test.drop(columns='floor_count')
clean_test = clean_test.drop(columns='year_built')

test_X = clean_test.to_numpy()
test_X = pca.incremental_pca(test_X, 3, 3000)
X_test_scaled = scaler.transform(test_X)
test_Y_predict = model.predict(X_test_scaled)
print(test_Y_predict.shape)
data.test_to_csv(test_Y_predict, 'submissions/test_random_regression_tree_pca.csv')